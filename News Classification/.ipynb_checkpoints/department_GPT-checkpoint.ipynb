{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5dd972-35e8-4c14-acc9-b5f78befac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 725555 documents from 'news_set' collection\n"
     ]
    }
   ],
   "source": [
    "# Load the training data from the MongoDb\n",
    "\n",
    "\n",
    "import spacy\n",
    "import pymongo\n",
    "\n",
    "# Load spaCy models\n",
    "nlp= spacy.load('archive/Model_tilldpt/')\n",
    "nlp_main = spacy.load('archive/Model_tillmainkeywords/')\n",
    "nlp_ind = spacy.load('archive/Model_industry/')\n",
    "nlp_company = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Connect to the MongoDB server\n",
    "client = pymongo.MongoClient(\"mongodb://Aditya:123456@20.25.72.14:27017/?authMechanism=DEFAULT&authSource=admin\")\n",
    "\n",
    "# Choose the 'news' database\n",
    "db = client['news']\n",
    "\n",
    "# Choose the 'news_set' collection\n",
    "collection = db['news_set']\n",
    "\n",
    "# Query all data and exclude the _id field\n",
    "query_result = collection.find({}, {\"_id\": 0})\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Loop through the query result and append each document to the list\n",
    "for item in query_result:\n",
    "    data_list.append(item)\n",
    "\n",
    "# Print the number of documents retrieved\n",
    "print(f\"Retrieved {len(data_list)} documents from 'news_set' collection\")\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d1e5fd-60bf-45cf-bc26-8362d7816eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_1= {\n",
    "    \"Engineering_dpt\": [\n",
    "    \"engineering\",\n",
    "    \"construction\",\n",
    "    \"infrastructure\",\n",
    "    \"automation\",\n",
    "    \"robotics\",\n",
    "    \"CAD/CAM\",\n",
    "    \"CNC/CMM\",\n",
    "    \"machining\",\n",
    "    \"welding\",\n",
    "    \"fabrication\",\n",
    "    \"mechanical engineering\",\n",
    "    \"civil engineering\",\n",
    "    \"electrical engineering\",\n",
    "    \"aerospace engineering\",\n",
    "    \"software engineering\",\n",
    "    \"chemical engineering\",\n",
    "    \"manufacturing\",\n",
    "    \"innovation\",\n",
    "    \"3D printing\",\n",
    "    \"additive manufacturing\"\n",
    "  ],\n",
    "  \"Legal_dpt\": [\n",
    "    \"Lawyer\",\n",
    "    \"Attorney\",\n",
    "    \"Court\",\n",
    "    \"Litigation\",\n",
    "    \"Arbitration\",\n",
    "    \"Appeals\",\n",
    "    \"Contract\",\n",
    "    \"Agreement\",\n",
    "    \"Legislation\",\n",
    "    \"Compliance\",\n",
    "    \"Statute\",\n",
    "    \"Regulation\",\n",
    "    \"Merger\",\n",
    "    \"Acquisition\",\n",
    "    \"Bankruptcy\",\n",
    "    \"Intellectual Property\",\n",
    "    \"Copyright\",\n",
    "    \"Trademark\",\n",
    "    \"Patent\",\n",
    "    \"Privacy\",\n",
    "    \"Security\",\n",
    "    \"Corporate Governance\"\n",
    "  ],\n",
    "  \"Operations_dpt\": [\n",
    "    \"operations strategy\",\n",
    "    \"operational efficiency\",\n",
    "    \"process optimization\",\n",
    "    \"supply chain\",\n",
    "    \"inventory management\",\n",
    "    \"cost reduction\",\n",
    "    \"resource allocation\",\n",
    "    \"operational excellence\",\n",
    "    \"operational risk management\",\n",
    "    \"operational agility\",\n",
    "    \"operational productivity\",\n",
    "    \"operational visibility\",\n",
    "    \"operational planning\",\n",
    "    \"operational performance\",\n",
    "    \"operational metrics\",\n",
    "    \"operational cost control\",\n",
    "    \"operational quality control\",\n",
    "    \"operational process improvement\"\n",
    "  ],\n",
    "  \"Leadership_dpt\": [\n",
    "    \"Leadership_dpt\",\n",
    "    \"Corporate Governance\",\n",
    "    \"Leadership Development\",\n",
    "    \"Strategic Planning\",\n",
    "    \"Organizational Culture\",\n",
    "    \"Change Management\",\n",
    "    \"Employee Engagement\",\n",
    "    \"Performance Management\",\n",
    "    \"Coaching\",\n",
    "    \"Mentoring\",\n",
    "    \"Team Building\",\n",
    "    \"Talent Acquisition\",\n",
    "    \"Succession Planning\"\n",
    "  ],\n",
    "  \"Consulting_dpt\": [\n",
    "    \"Consulting\",\n",
    "    \"Advisory\",\n",
    "    \"Strategic Planning\",\n",
    "    \"Business Transformation\",\n",
    "    \"Change Management\",\n",
    "    \"Process Reengineering\",\n",
    "    \"Corporate Restructuring\",\n",
    "    \"Mergers & Acquisitions\",\n",
    "    \"Business Process Optimization\",\n",
    "    \"Business Analysis\",\n",
    "    \"Risk Management\",\n",
    "    \"Financial Modeling\",\n",
    "    \"Business Intelligence\",\n",
    "    \"Market Research\",\n",
    "    \"Project Management\"\n",
    "  ],\n",
    "  \"Sales_dpt\": [\n",
    "    \"Sales\",\n",
    "    \"revenue\",\n",
    "    \"customer\",\n",
    "    \"client\",\n",
    "    \"account\",\n",
    "    \"quota\",\n",
    "    \"forecast\",\n",
    "    \"deal\",\n",
    "    \"product\",\n",
    "    \"market share\",\n",
    "    \"pricing\",\n",
    "    \"promotion\",\n",
    "    \"strategy\",\n",
    "    \"performance\",\n",
    "    \"analysis\",\n",
    "    \"target\",\n",
    "    \"goal\",\n",
    "    \"order\",\n",
    "    \"commission\",\n",
    "    \"ROI\",\n",
    "    \"customer satisfaction\"\n",
    "  ],\n",
    "  \"Purchasing&Logistics_dpt\": [\n",
    "    \"purchasing\",\n",
    "    \"logistics\",\n",
    "    \"inventory\",\n",
    "    \"supply chain\",\n",
    "    \"procurement\",\n",
    "    \"sourcing\",\n",
    "    \"shipping\",\n",
    "    \"delivery\",\n",
    "    \"warehousing\",\n",
    "    \"transportation\",\n",
    "    \"materials management\",\n",
    "    \"cost savings\",\n",
    "    \"vendor management\",\n",
    "    \"cycle time\",\n",
    "    \"order fulfillment\",\n",
    "    \"inventory control\",\n",
    "    \"category management\",\n",
    "    \"cost optimization\",\n",
    "    \"supplier development\",\n",
    "    \"supplier relationships\",\n",
    "    \"shipping and receiving\",\n",
    "    \"demand forecasting\"\n",
    "  ],\n",
    "  \"Administrative_dpt\": [\n",
    "    \"Administrative_dpt\",\n",
    "    \"Office Management\",\n",
    "    \"Organizational Skills\",\n",
    "    \"Staffing and Recruitment\",\n",
    "    \"Regulatory Compliance\",\n",
    "    \"Budgeting and Financial Planning\",\n",
    "    \"Performance Management\",\n",
    "    \"Project Management\",\n",
    "    \"Communication and Negotiation\",\n",
    "    \"Customer Service\",\n",
    "    \"Conflict Resolution\"\n",
    "  ],\n",
    "  \"HospitalityTourismResturants_dpt\": [\n",
    "    \"Restaurant\",\n",
    "    \"Hospitality\",\n",
    "    \"Tourism\",\n",
    "    \"Hotel\",\n",
    "    \"Resort\",\n",
    "    \"Food Service\",\n",
    "    \"Dining\",\n",
    "    \"Cuisine\",\n",
    "    \"Bar\",\n",
    "    \"Banquet\",\n",
    "    \"Catering\",\n",
    "    \"Lodging\",\n",
    "    \"Accommodation\",\n",
    "    \"Airline\",\n",
    "    \"Cruise\",\n",
    "    \"Travel\",\n",
    "    \"Trip\",\n",
    "    \"Vacation\",\n",
    "    \"Spa\",\n",
    "    \"Wellness\",\n",
    "    \"Leisure\",\n",
    "    \"Entertainment\",\n",
    "    \"Casino\",\n",
    "    \"Transportation\",\n",
    "    \"Attraction\"\n",
    "  ],\n",
    "  \"ArtsandDesign_dpt\": [\n",
    "    \"arts\",\n",
    "    \"design\",\n",
    "    \"architecture\",\n",
    "    \"sculpture\",\n",
    "    \"painting\",\n",
    "    \"drawing\",\n",
    "    \"illustration\",\n",
    "    \"photography\",\n",
    "    \"fashion\",\n",
    "    \"textiles\",\n",
    "    \"crafts\",\n",
    "    \"graphic design\",\n",
    "    \"ceramics\",\n",
    "    \"performance art\",\n",
    "    \"multimedia\",\n",
    "    \"video art\",\n",
    "    \"installation art\",\n",
    "    \"interior design\"\n",
    "  ],\n",
    "  \"BusinessDevelopment_dpt\": [\n",
    "    \"Business Development\",\n",
    "    \"Mergers & Acquisitions\",\n",
    "    \"Strategic Alliances\",\n",
    "    \"Growth Strategies\",\n",
    "    \"Market Expansion\",\n",
    "    \"New Ventures\",\n",
    "    \"Product Line Expansion\",\n",
    "    \"Sales & Distribution\",\n",
    "    \"Customer Relations\",\n",
    "    \"Competitive Strategies\",\n",
    "    \"Financial Modeling\",\n",
    "    \"Risk Management\",\n",
    "    \"Market Research\",\n",
    "    \"Business Planning\",\n",
    "    \"Corporate Restructuring\",\n",
    "    \"Branding\",\n",
    "    \"Corporate Social Responsibility\"\n",
    "  ],\n",
    "  \"MilitaryandProtectiveService_dpt\": [\n",
    "    \"Military\",\n",
    "    \"Protective Service\",\n",
    "    \"Armed Forces\",\n",
    "    \"National Defense\",\n",
    "    \"Intelligence\",\n",
    "    \"Security\",\n",
    "    \"Counterterrorism\",\n",
    "    \"Cyber Security\",\n",
    "    \"Border Protection\",\n",
    "    \"Crisis Response\",\n",
    "    \"Emergency Management\",\n",
    "    \"Military Training\",\n",
    "    \"Weapons Systems\",\n",
    "    \"Logistics\",\n",
    "    \"Combat\",\n",
    "    \"Defense Spending\",\n",
    "    \"Arms Control\",\n",
    "    \"Peacekeeping\"\n",
    "  ],\n",
    "  \"Owners_dpt\": [\n",
    "    \"Owners_dpt\",\n",
    "    \"ownership\",\n",
    "    \"shareholders\",\n",
    "    \"stockholders\",\n",
    "    \"equity\",\n",
    "    \"investments\",\n",
    "    \"dividends\",\n",
    "    \"financials\",\n",
    "    \"governance\",\n",
    "    \"fiduciary\",\n",
    "    \"capitalization\",\n",
    "    \"valuation\",\n",
    "    \"stakeholder\",\n",
    "    \"economic interests\",\n",
    "    \"capital structure\",\n",
    "    \"returns\",\n",
    "    \"performance\",\n",
    "    \"board of directors\",\n",
    "    \"executive management\",\n",
    "    \"operational data\",\n",
    "    \"financial reports\",\n",
    "    \"risk management\",\n",
    "    \"compliance\",\n",
    "    \"auditing\",\n",
    "    \"regulatory compliance\"\n",
    "  ],\n",
    "  \"HealthCare_dpt\": [\n",
    "    \"healthcare\",\n",
    "    \"health\",\n",
    "    \"medical\",\n",
    "    \"pharmaceutical\",\n",
    "    \"biotechnology\",\n",
    "    \"hospital\",\n",
    "    \"clinic\",\n",
    "    \"physician\",\n",
    "    \"nurse\",\n",
    "    \"healthcare providers\",\n",
    "    \"healthcare IT\",\n",
    "    \"healthcare reform\",\n",
    "    \"insurance\",\n",
    "    \"telemedicine\",\n",
    "    \"managed care\",\n",
    "    \"patient care\",\n",
    "    \"preventive care\",\n",
    "    \"public health\",\n",
    "    \"clinical trials\",\n",
    "    \"medical research\",\n",
    "    \"Medicaid\",\n",
    "    \"Medicare\",\n",
    "    \"prescription drugs\",\n",
    "    \"drug prices\",\n",
    "    \"health savings accounts\"\n",
    "  ],\n",
    "  \"Trades_dpt\": [\n",
    "    \"Trades_dpt\",\n",
    "    \"trade-related\",\n",
    "    \"trades\",\n",
    "    \"trade-related services\",\n",
    "    \"commodities trading\",\n",
    "    \"import/export\",\n",
    "    \"import/export regulations\",\n",
    "    \"foreign exchange\",\n",
    "    \"foreign exchange markets\",\n",
    "    \"market analysis\",\n",
    "    \"risk management\",\n",
    "    \"hedging\",\n",
    "    \"financial instruments\",\n",
    "    \"contracts\",\n",
    "    \"supply chain\",\n",
    "    \"logistics\",\n",
    "    \"shipping\",\n",
    "    \"transportation\",\n",
    "    \"warehousing\",\n",
    "    \"tariffs\",\n",
    "    \"customs regulations\"\n",
    "  ],\n",
    "  \"Research_dpt\": [\n",
    "    \"research papers\",\n",
    "    \"scientific studies\",\n",
    "    \"technology advancements\",\n",
    "    \"innovation\",\n",
    "    \"data analytics\",\n",
    "    \"artificial intelligence\",\n",
    "    \"machine learning\",\n",
    "    \"big data\",\n",
    "    \"quantum computing\",\n",
    "    \"robotics\",\n",
    "    \"nanotechnology\",\n",
    "    \"biochemistry\",\n",
    "    \"biophysics\",\n",
    "    \"bioinformatics\",\n",
    "    \"genetic engineering\",\n",
    "    \"cell biology\",\n",
    "    \"neuroscience\",\n",
    "    \"immunology\",\n",
    "    \"epidemiology\",\n",
    "    \"molecular biology\",\n",
    "    \"biotechnology\",\n",
    "    \"pharmacology\",\n",
    "    \"computational biology\",\n",
    "    \"clinical trials\",\n",
    "    \"drug discovery\",\n",
    "    \"genomics\",\n",
    "    \"proteomics\",\n",
    "    \"bioengineering\",\n",
    "    \"medical devices\"\n",
    "  ],\n",
    "  \"Support_dpt\": [\n",
    "    \"Help Desk\",\n",
    "    \"Technical Support\",\n",
    "    \"Troubleshooting\",\n",
    "    \"System Maintenance\",\n",
    "    \"Problem-Solving\",\n",
    "    \"Issue Resolution\",\n",
    "    \"Incident Management\",\n",
    "    \"Software Updates\",\n",
    "    \"Network Administration\",\n",
    "    \"User Training\",\n",
    "    \"Customer Service\"\n",
    "  ],\n",
    "  \"Marketing_dpt\": [\n",
    "    \"branding\",\n",
    "    \"advertising\",\n",
    "    \"customer engagement\",\n",
    "    \"market research\",\n",
    "    \"market segmentation\",\n",
    "    \"customer loyalty\",\n",
    "    \"digital marketing\",\n",
    "    \"content marketing\",\n",
    "    \"influencer marketing\",\n",
    "    \"public relations\",\n",
    "    \"customer service\",\n",
    "    \"product launches\",\n",
    "    \"market trends\",\n",
    "    \"competitive analysis\",\n",
    "    \"customer experience\",\n",
    "    \"social media marketing\",\n",
    "    \"ROI\",\n",
    "    \"analytics\"\n",
    "  ],\n",
    "  \"ProductManagement_dpt\": [\n",
    "    \"Product Roadmap\",\n",
    "    \"Product Launch\",\n",
    "    \"Product Lifecycle\",\n",
    "    \"Product Design\",\n",
    "    \"Product Management\",\n",
    "    \"Product Development\",\n",
    "    \"Product Optimization\",\n",
    "    \"Product Requirements\",\n",
    "    \"Product Strategy\",\n",
    "    \"Product Enhancement\",\n",
    "    \"User Experience\",\n",
    "    \"Value Proposition\",\n",
    "    \"Market Research\",\n",
    "    \"Competitive Analysis\",\n",
    "    \"Cost Analysis\",\n",
    "    \"Pricing Strategy\",\n",
    "    \"Customer Feedback\",\n",
    "    \"Product Iteration\",\n",
    "    \"Feature Prioritization\",\n",
    "    \"Development Timeline\",\n",
    "    \"Release Cycle\",\n",
    "    \"Market Trends\"\n",
    "  ],\n",
    "  \"IT_dpt\": [\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Cloud Computing\",\n",
    "    \"Big Data\",\n",
    "    \"Robotics\",\n",
    "    \"Blockchain\",\n",
    "    \"Data Science\",\n",
    "    \"Machine Learning\",\n",
    "    \"Internet of Things\",\n",
    "    \"Augmented Reality\",\n",
    "    \"Virtual Reality\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Software Development\",\n",
    "    \"Network Security\",\n",
    "    \"IT Infrastructure\",\n",
    "    \"Data Management\",\n",
    "    \"DevOps\",\n",
    "    \"Mobility Solutions\",\n",
    "    \"Data Analytics\"\n",
    "  ],\n",
    "  \"CLevel_dpt\": [\n",
    "    \"Leadership\",\n",
    "    \"Strategy\",\n",
    "    \"Management\",\n",
    "    \"Performance\",\n",
    "    \"Culture\",\n",
    "    \"Innovation\",\n",
    "    \"Collaboration\",\n",
    "    \"Efficiency\",\n",
    "    \"ROI\",\n",
    "    \"Change\",\n",
    "    \"Talent\",\n",
    "    \"Growth\",\n",
    "    \"Productivity\",\n",
    "    \"Quality\",\n",
    "    \"Cost Reduction\",\n",
    "    \"Risk Management\",\n",
    "    \"Market Expansion\"\n",
    "  ],\n",
    "  \"ProgramandProjectManagement_dpt\": [\n",
    "    \"Project Management\",\n",
    "    \"Program Management\",\n",
    "    \"Project Planning\",\n",
    "    \"Risk Management\",\n",
    "    \"Change Management\",\n",
    "    \"Quality Control\",\n",
    "    \"Resource Allocation\",\n",
    "    \"Cost Estimation\",\n",
    "    \"Scheduling\",\n",
    "    \"Leadership\",\n",
    "    \"Team Building\",\n",
    "    \"Collaboration\",\n",
    "    \"Communication\",\n",
    "    \"Technical Analysis\",\n",
    "    \"Agile Methodology\",\n",
    "    \"Business Analysis\",\n",
    "    \"Stakeholder Engagement\",\n",
    "    \"Requirements Analysis\",\n",
    "    \"Process Improvement\",\n",
    "    \"Budgeting\",\n",
    "    \"Earned Value Management\"\n",
    "  ],\n",
    "  \"RealEstate_dpt\": [\n",
    "    \"Real estate\",\n",
    "    \"property\",\n",
    "    \"housing market\",\n",
    "    \"mortgages\",\n",
    "    \"home sales\",\n",
    "    \"prices\",\n",
    "    \"affordability\",\n",
    "    \"inventory\",\n",
    "    \"construction\",\n",
    "    \"zoning\",\n",
    "    \"land development\",\n",
    "    \"commercial real estate\",\n",
    "    \"investment\",\n",
    "    \"brokers\",\n",
    "    \"leasing\",\n",
    "    \"tenant\",\n",
    "    \"landlord\",\n",
    "    \"appraisals\",\n",
    "    \"development\",\n",
    "    \"housing finance\",\n",
    "    \"REITs\",\n",
    "    \"homebuilders\",\n",
    "    \"homebuyers\"\n",
    "  ],\n",
    "  \"CommunityandSocialServices_dpt\": [\n",
    "    \"community services\",\n",
    "    \"social services\",\n",
    "    \"housing assistance\",\n",
    "    \"income support\",\n",
    "    \"disability support\",\n",
    "    \"child care\",\n",
    "    \"job training\",\n",
    "    \"employment assistance\",\n",
    "    \"poverty reduction\",\n",
    "    \"homelessness\",\n",
    "    \"mental health services\",\n",
    "    \"addiction services\",\n",
    "    \"family services\",\n",
    "    \"youth services\",\n",
    "    \"seniors services\",\n",
    "    \"Indigenous services\",\n",
    "    \"refugee services]\"\n",
    "  ],\n",
    "  \"Entrepreneurship_dpt\": [\n",
    "    \"Entrepreneurship\",\n",
    "    \"Start-up\",\n",
    "    \"Business plan\",\n",
    "    \"Venture Capital\",\n",
    "    \"Angel Investors\",\n",
    "    \"Incubation\",\n",
    "    \"Innovation\",\n",
    "    \"Market Research\",\n",
    "    \"Funding\",\n",
    "    \"Crowdfunding\",\n",
    "    \"Product Development\",\n",
    "    \"Risk Management\",\n",
    "    \"Exit Strategy\",\n",
    "    \"Financial Modeling\",\n",
    "    \"Business Model\"\n",
    "  ],\n",
    "  \"HumanResources_dpt\": [\n",
    "    \"HR\",\n",
    "    \"Recruiting\",\n",
    "    \"Retention\",\n",
    "    \"Compensation\",\n",
    "    \"Benefits\",\n",
    "    \"Diversity\",\n",
    "    \"Training and Development\",\n",
    "    \"Performance Management\",\n",
    "    \"Labor Relations\",\n",
    "    \"HR Technology\",\n",
    "    \"Culture\",\n",
    "    \"Organizational Development\"\n",
    "  ],\n",
    "  \"Education_dpt\": [\n",
    "    \"Education\",\n",
    "    \"School\",\n",
    "    \"Teacher\",\n",
    "    \"Student\",\n",
    "    \"Curriculum\",\n",
    "    \"Learning\",\n",
    "    \"Technology\",\n",
    "    \"Innovation\",\n",
    "    \"Assessment\",\n",
    "    \"Funding\",\n",
    "    \"Scholarship\",\n",
    "    \"Classroom\",\n",
    "    \"Graduation\",\n",
    "    \"College\",\n",
    "    \"University\"\n",
    "  ],\n",
    "  \"Others_dpt\": [\n",
    "    \"Human Resources\",\n",
    "    \"Talent Management\",\n",
    "    \"Employee Retention\",\n",
    "    \"Compensation\",\n",
    "    \"Benefits\",\n",
    "    \"Employee Engagement\",\n",
    "    \"Diversity\",\n",
    "    \"Inclusion\",\n",
    "    \"Leadership Development\",\n",
    "    \"Training\",\n",
    "    \"Coaching\",\n",
    "    \"Organizational Development\",\n",
    "    \"Succession Planning\",\n",
    "    \"Recruiting\",\n",
    "    \"Performance Management\",\n",
    "    \"Workplace Safety\",\n",
    "    \"Policy Development\",\n",
    "    \"Regulatory Compliance\",\n",
    "    \"Conflict Resolution\"\n",
    "  ],\n",
    "  \"QualityAssurance_dpt\": [\n",
    "    \"Quality Assurance\",\n",
    "    \"Quality Control\",\n",
    "    \"Quality Management\",\n",
    "    \"Quality Testing\",\n",
    "    \"Test Automation\",\n",
    "    \"Quality Metrics\",\n",
    "    \"Test Strategies\",\n",
    "    \"Process Improvement\",\n",
    "    \"Quality Auditing\",\n",
    "    \"Quality Standards\",\n",
    "    \"Quality Documentation\",\n",
    "    \"Performance Metrics\",\n",
    "    \"Risk Management\",\n",
    "    \"Root Cause Analysis\",\n",
    "    \"Defect Tracking\",\n",
    "    \"Regulatory Compliance\",\n",
    "    \"Quality Plans\",\n",
    "    \"Quality Analysis\",\n",
    "    \"Quality Assurance Plans\",\n",
    "    \"Quality Assurance Procedures\"\n",
    "  ],\n",
    "  \"Accounting_dpt\": [\n",
    "    \"Accounting\",\n",
    "    \"Financial Statements\",\n",
    "    \"Balance Sheet\",\n",
    "    \"Profit & Loss\",\n",
    "    \"Cash Flow\",\n",
    "    \"Ledger\",\n",
    "    \"Taxation\",\n",
    "    \"Auditing\",\n",
    "    \"Budgeting\",\n",
    "    \"Costing\",\n",
    "    \"Reconciliation\",\n",
    "    \"Return on Investment (ROI)\",\n",
    "    \"Debits & Credits\",\n",
    "    \"Accounts Receivable/Payable\",\n",
    "    \"Cash Management\",\n",
    "    \"Sarbanes-Oxley (SOX)\",\n",
    "    \"GAAP (Generally Accepted Accounting Principles)\",\n",
    "    \"Bookkeeping\",\n",
    "    \"Fraud Prevention\",\n",
    "    \"Internal Controls\"\n",
    "  ],\n",
    "  \"Finance_dpt\": [\n",
    "    \"stock market\",\n",
    "    \"Wall Street\",\n",
    "    \"earnings\",\n",
    "    \"bonds\",\n",
    "    \"IPO\",\n",
    "    \"derivatives\",\n",
    "    \"derivatives market\",\n",
    "    \"risk management\",\n",
    "    \"banking\",\n",
    "    \"financial analysis\",\n",
    "    \"balance sheet\",\n",
    "    \"mergers and acquisitions\",\n",
    "    \"venture capital\",\n",
    "    \"hedge funds\",\n",
    "    \"asset management\",\n",
    "    \"private equity\",\n",
    "    \"dividends\",\n",
    "    \"credit rating\",\n",
    "    \"liquidity\",\n",
    "    \"fiscal year\",\n",
    "    \"capital gains\",\n",
    "    \"portfolio\",\n",
    "    \"mutual funds\",\n",
    "    \"venture financing\",\n",
    "    \"hedge fund strategies\",\n",
    "    \"derivatives trading\",\n",
    "    \"capital markets\",\n",
    "    \"debt restructuring\",\n",
    "    \"corporate finance\",\n",
    "    \"commodities\",\n",
    "    \"derivatives pricing\"\n",
    "  ],\n",
    "  \"MediaandCommunication_dpt\": [\n",
    "    \"Media\",\n",
    "    \"Communications\",\n",
    "    \"Public Relations\",\n",
    "    \"Marketing\",\n",
    "    \"Advertising\",\n",
    "    \"Journalism\",\n",
    "    \"Broadcasting\",\n",
    "    \"Publishing\",\n",
    "    \"Social Media\",\n",
    "    \"Digital Media\",\n",
    "    \"Content Management\",\n",
    "    \"Online Strategies\",\n",
    "    \"Social Media Strategies\",\n",
    "    \"Digital Strategies\",\n",
    "    \"Branding\",\n",
    "    \"Media Relations\",\n",
    "    \"Publicity\",\n",
    "    \"Storytelling\",\n",
    "    \"Audience Engagement\",\n",
    "    \"Media Coverage\",\n",
    "    \"Media Planning\",\n",
    "    \"Media Analysis\"\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6fa0cf-1012-43f4-a00f-6421732b69ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of TRAIN_DATA is 2868 \n"
     ]
    }
   ],
   "source": [
    "# In[8]: Converting the Dataset to format on which SpaCy NER model trains\n",
    "\n",
    "nlpe = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add entity labels to the NER model\n",
    "ner = nlpe.get_pipe(\"ner\")\n",
    "for entity, keywords_list in keywords_1.items():\n",
    "    ner.add_label(entity)\n",
    "\n",
    "# Initialize the training data\n",
    "TRAIN_DATA = []\n",
    "\n",
    "# Function to find entities in the text and label them\n",
    "def label_entities(text, keywords):\n",
    "    entities = []\n",
    "    words = text.split()  # Split the text into words\n",
    "    for entity, keywords_list in keywords.items():\n",
    "        for keyword in keywords_list:\n",
    "            for word in words:\n",
    "                if word.lower() == keyword.lower():  # Check for a whole word match\n",
    "                    start = text.find(word)\n",
    "                    end = start + len(word)\n",
    "                    entities.append((start, end, entity))\n",
    "    return entities\n",
    "\n",
    "# Generate training data for the first 1000 news headlines\n",
    "for item in data_list[:10000]:\n",
    "    if 'news' in item and 'head' in item['news']:\n",
    "        text = item['news']['head']\n",
    "        entities = label_entities(text, keywords_1)\n",
    "        if entities:\n",
    "            # Sort entities by start position to avoid overlap\n",
    "            entities.sort(key=lambda x: x[0])\n",
    "            # Only label the first entity found\n",
    "            TRAIN_DATA.append((text, {'entities': entities[:1]}))\n",
    "\n",
    "print(f\"the length of TRAIN_DATA is {len(TRAIN_DATA)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf06807-c4fe-4c18-96d5-4396aa410abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of training data is2868\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of training data is{len(TRAIN_DATA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d00815e-5843-443e-9b82-ce274d02deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook department_train.ipynb to python\n",
      "[NbConvertApp] Writing 17974 bytes to department_train.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python department_train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a304c2e-4dd4-4142-a069-9b5f70b5f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET = TRAIN_DATA\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "# Define the pipeline component name\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Disable other pipeline components to only train NER\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    # Set up the training loop\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    # Training parameters\n",
    "    batch_size = 32\n",
    "    best_loss = float(\"inf\")\n",
    "    patience = 3  # Number of iterations without improvement to tolerate before early stopping\n",
    "\n",
    "    # Shuffle the data for randomness\n",
    "    random.shuffle(TRAIN_SET)\n",
    "\n",
    "    # Define the split ratio (e.g., 80% train, 20% validation)\n",
    "    split_ratio = 0.8\n",
    "    split_index = int(len(TRAIN_SET) * split_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = TRAIN_SET[:split_index]\n",
    "    valid_data = TRAIN_SET[split_index:]\n",
    "\n",
    "    consecutive_no_improvement = 0  # Counter for consecutive iterations without improvement\n",
    "\n",
    "    # Function to train the model on a batch and calculate time taken\n",
    "    def train_batch(batch):\n",
    "        texts, annotations = zip(*batch)\n",
    "        example = []\n",
    "        # Update the examples with the annotations\n",
    "        for i in range(len(texts)):\n",
    "            doc = nlp.make_doc(texts[i])\n",
    "            example.append(Example.from_dict(doc, annotations[i]))\n",
    "        start_time = time.time()\n",
    "        nlp.update(example, drop=0.5, losses=losses)\n",
    "        end_time = time.time()\n",
    "        return end_time - start_time\n",
    "\n",
    "    # Function to evaluate the model on a batch\n",
    "    def evaluate_batch(batch):\n",
    "        valid_loss_ner = 0.0\n",
    "        num_valid_examples = len(batch)\n",
    "        for text, annot in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annot)\n",
    "            eval_loss = nlp.evaluate([example])\n",
    "            valid_loss_ner += eval_loss.get(\"ner\", 0.0)\n",
    "        return valid_loss_ner, num_valid_examples\n",
    "\n",
    "    while consecutive_no_improvement < patience:\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        training_times = []\n",
    "\n",
    "        # Use multiprocessing to train in parallel\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "        batches = minibatch(train_data, size=batch_size)\n",
    "        training_times = pool.map(train_batch, batches)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        # Validate the model\n",
    "        valid_loss_ner = 0.0\n",
    "        num_valid_examples = 0\n",
    "\n",
    "        # Evaluate validation data in batches\n",
    "        batch_size_eval = 32\n",
    "        for i in range(0, len(valid_data), batch_size_eval):\n",
    "            batch = valid_data[i:i + batch_size_eval]\n",
    "            loss, num_examples = evaluate_batch(batch)\n",
    "            valid_loss_ner += loss\n",
    "            num_valid_examples += num_examples\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        average_valid_loss = valid_loss_ner / num_valid_examples\n",
    "\n",
    "        # Check for improvement in validation loss\n",
    "        if average_valid_loss < best_loss:\n",
    "            best_loss = average_valid_loss\n",
    "            nlp.to_disk(\"archive/updated_Department_py\")\n",
    "            consecutive_no_improvement = 0  # Reset the counter\n",
    "        else:\n",
    "            consecutive_no_improvement += 1\n",
    "\n",
    "        # Calculate and log the average training time for this epoch\n",
    "        average_training_time = sum(training_times) / len(training_times)\n",
    "        with open(\"training_logs_ind.txt\", \"a\") as log_file:\n",
    "            log_entry = f\"Iteration {consecutive_no_improvement} - Train Loss: {losses['ner']:.2f} - Valid Loss: {average_valid_loss:.2f} - Epoch Time: {average_training_time:.2f} seconds\"\n",
    "            print(log_entry)  # Print the log entry\n",
    "            log_file.write(log_entry + \"\\n\")  # Save the log entry to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model \n",
    "\n",
    "import spacy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from spacy.training.example import Example\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"[W030]\")\n",
    "import sys\n",
    "\n",
    "# Split TRAIN_DATA into training and validation sets\n",
    "train_data, validation_data = train_test_split(TRAIN_DATA, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add labels from your existing model\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get('entities'):\n",
    "        nlp.get_pipe(\"ner\").add_label(ent[2])\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    best_loss = float('inf')  # Initialize a variable to track the best loss\n",
    "    best_model = None  # Initialize a variable to store the best model\n",
    "    n_iter = 1000  # Set the number of training iterations\n",
    "    start_time = time.time()  # Record the start time\n",
    "\n",
    "    def train_text(text_annotation):\n",
    "        text, annotations = text_annotation\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        losses = {}\n",
    "        nlp.update([example], drop=0.5, losses=losses)\n",
    "        return losses\n",
    "\n",
    "    consecutive_no_improvement = 0  # Initialize a counter for consecutive epochs with no improvement\n",
    "    early_stopping_patience = 10  # Define the patience (number of epochs with no improvement before stopping)\n",
    "\n",
    "    training_logs = []  # Initialize a list to store training logs\n",
    "\n",
    "    # Redirect stdout to a log file\n",
    "    log_file = open(\"training_department_model.txt\", \"w\")\n",
    "    sys.stdout = log_file\n",
    "\n",
    "    with Pool() as pool:  # Use multiprocessing for faster training\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(train_data)  # Shuffle the training data\n",
    "\n",
    "            # Training\n",
    "            loss_results = list(tqdm(pool.imap(train_text, train_data), total=len(train_data)))\n",
    "            total_loss = sum(loss['ner'] for loss in loss_results)\n",
    "            average_loss = total_loss / len(train_data)\n",
    "\n",
    "            # Validation\n",
    "            validation_loss_results = list(tqdm(pool.imap(train_text, validation_data), total=len(validation_data)))\n",
    "            validation_total_loss = sum(loss['ner'] for loss in validation_loss_results)\n",
    "            validation_average_loss = validation_total_loss / len(validation_data)\n",
    "\n",
    "            end_time = time.time()  # Record the end time\n",
    "            time_taken = end_time - start_time  # Calculate the time taken for this iteration\n",
    "\n",
    "            if validation_average_loss < best_loss:\n",
    "                best_loss = validation_average_loss\n",
    "                best_model = nlp.to_bytes()  # Save the best model\n",
    "                consecutive_no_improvement = 0  # Reset the counter\n",
    "                log = f\"Iteration {itn + 1}: Best training loss: {average_loss:.4f}, Validation loss: {validation_average_loss:.4f}, Time taken: {time_taken:.2f} seconds\"\n",
    "                training_logs.append(log)\n",
    "                print(log)\n",
    "            else:\n",
    "                consecutive_no_improvement += 1\n",
    "\n",
    "                if consecutive_no_improvement >= early_stopping_patience:\n",
    "                    log = f\"Early stopping at iteration {itn + 1}: Validation loss has not improved for {early_stopping_patience} consecutive epochs.\"\n",
    "                    training_logs.append(log)\n",
    "                    print(log)\n",
    "                    break\n",
    "                else:\n",
    "                    log = f\"Iteration {itn + 1}: Training loss: {average_loss:.4f}, Validation loss: {validation_average_loss:.4f}, Time taken: {time_taken:.2f} seconds\"\n",
    "                    training_logs.append(log)\n",
    "                    print(log)\n",
    "\n",
    "    # Save the training logs to a file\n",
    "    with open(\"training_department_model.txt\", \"w\") as log_file:\n",
    "        for log in training_logs:\n",
    "            log_file.write(log + \"\\n\")\n",
    "\n",
    "    # Save the best model to disk\n",
    "    nlp.to_disk(\"archive/updated_Department_py\")\n",
    "\n",
    "    # Close the log file and reset stdout\n",
    "    log_file.close()\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "print(\"Training completed with early stopping.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
