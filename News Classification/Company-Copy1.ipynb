{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c67823-6459-47fd-afa6-2e8476590a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 725555 documents from 'news_set' collection\n"
     ]
    }
   ],
   "source": [
    "# Load the data from MongoDB and convert them to a python dictionary \n",
    "import spacy\n",
    "import pymongo\n",
    "\n",
    "# Load spaCy models\n",
    "nlp_dpt = spacy.load('archive/Model_tilldpt/')\n",
    "nlp_main = spacy.load('archive/Model_tillmainkeywords/')\n",
    "nlp_ind = spacy.load('archive/Model_industry/')\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Connect to the MongoDB server\n",
    "client = pymongo.MongoClient(\"mongodb://Aditya:123456@20.25.72.14:27017/?authMechanism=DEFAULT&authSource=admin\")\n",
    "\n",
    "# Choose the 'news' database\n",
    "db = client['news']\n",
    "\n",
    "# Choose the 'news_set' collection\n",
    "collection = db['news_set']\n",
    "\n",
    "# Query all data and exclude the _id field\n",
    "query_result = collection.find({}, {\"_id\": 0})\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Loop through the query result and append each document to the list\n",
    "for item in query_result:\n",
    "    data_list.append(item)\n",
    "\n",
    "# Print the number of documents retrieved\n",
    "print(f\"Retrieved {len(data_list)} documents from 'news_set' collection\")\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df063d6c-6968-47c6-94f6-381a4072ab13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cmp_name': 'Inter Pipeline',\n",
       " 'news': {'date': 'Sep 22, 2021',\n",
       "  'src': 'Yahoo Finance',\n",
       "  'head': 'Inter Pipeline CEO, CFO to step down; Brookfield executives to assume interim roles',\n",
       "  'link': 'https://finance.yahoo.com/news/inter-pipeline-ceo-cfo-step-013748079.html'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65296f7-9c0d-4c96-8dc5-3e45624f546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of TRAIN_DATA is 58 \n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "for data in data_list[:100]:\n",
    "    company_name = data['cmp_name']\n",
    "    headline = data['news']['head']\n",
    "    start_index = headline.find(company_name)  # Find the starting index of 'cmp_name' in 'head'\n",
    "    \n",
    "    if start_index != -1:  # Check if 'cmp_name' is found in 'head'\n",
    "        end_index = start_index + len(company_name)  # Calculate the end index\n",
    "        training_data.append((headline, {'entities': [(start_index, end_index, 'ORG')]}) )\n",
    "print(f\"the length of TRAIN_DATA is {len(training_data)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0989f-48e6-4d1a-8a2b-3abedc27e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys  # Import the sys module\n",
    "from spacy.training.example import Example\n",
    "\n",
    "# Load the base model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Add the new entity label 'ORG' to the NER pipeline\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.add_label(\"ORG\")\n",
    "\n",
    "# Save the training logs to a text file\n",
    "log_file = open(\"org_py.txt\", \"w\")\n",
    "\n",
    "for epoch in range(25):\n",
    "    for text, annotations in training_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        \n",
    "        # Create a buffer for capturing training logs\n",
    "        log_buffer = []\n",
    "\n",
    "        def custom_log(s, *args, ends=\"\"):\n",
    "            print(s.format(*args), end=ends)\n",
    "            print(s.format(*args), end=ends, file=log_file)\n",
    "        \n",
    "        # Redirect the standard output to the buffer\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = log_buffer\n",
    "        \n",
    "        # Update the model\n",
    "        with nlp.select_pipes(enable=[\"ner\"]):\n",
    "            with nlp.disable_pipes(\"ner\"):\n",
    "                custom_log(\"Epoch: {}\", epoch)\n",
    "                custom_log(\"Text: {}\", text)\n",
    "                nlp.update([example], drop=0.5)\n",
    "        \n",
    "        # Restore the standard output\n",
    "        sys.stdout = original_stdout\n",
    "        \n",
    "        # Write the buffer contents to the log file\n",
    "        log_file.writelines(log_buffer)\n",
    "        log_file.flush()\n",
    "\n",
    "# Close the log file\n",
    "log_file.close()\n",
    "\n",
    "# Save the trained model\n",
    "output_dir = \"archive/updated_CompanyModel_py\"\n",
    "nlp.to_disk(output_dir)\n",
    "\n",
    "print(\"NER model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a71c99-5f0d-4060-a37f-3efdad740491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "from spacy.training.example import Example\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Load the base model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Add the new entity label 'ORG' to the NER pipeline\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.add_label(\"ORG\")\n",
    "\n",
    "# Load your training data (assuming you have a list of tuples: (text, annotations))\n",
    "# Replace `training_data` with your actual data\n",
    "# training_data = ...\n",
    "\n",
    "# Split your data into a training and test set (70% train, 30% test)\n",
    "train_data, test_data = train_test_split(training_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Save the training logs to a text file\n",
    "log_file = open(\"org_py.txt\", \"w\")\n",
    "\n",
    "def train_epoch(epoch):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for text, annotations in train_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "\n",
    "        # Create a buffer for capturing training logs\n",
    "        log_buffer = []\n",
    "\n",
    "        def custom_log(s, *args, ends=\"\"):\n",
    "            print(s.format(*args), end=ends)\n",
    "            print(s.format(*args), end=ends, file=log_file)\n",
    "\n",
    "        # Redirect the standard output to the buffer\n",
    "        original_stdout = sys.stdout\n",
    "        sys.stdout = log_buffer\n",
    "\n",
    "        # Update the model\n",
    "        with nlp.select_pipes(enable=[\"ner\"]):\n",
    "            with nlp.disable_pipes(\"ner\"):\n",
    "                custom_log(\"Epoch: {}\", epoch)\n",
    "                custom_log(\"Text: {}\", text)\n",
    "                nlp.update([example], drop=0.5)\n",
    "\n",
    "        # Restore the standard output\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "        # Write the buffer contents to the log file\n",
    "        log_file.writelines(log_buffer)\n",
    "        log_file.flush()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    custom_log(\"Time taken for epoch {}: {:.2f} seconds\", epoch, epoch_time)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 25\n",
    "\n",
    "# Use multi-threading to train the model\n",
    "with Pool(processes=4) as pool:\n",
    "    pool.map(train_epoch, range(num_epochs))\n",
    "\n",
    "# Close the log file\n",
    "log_file.close()\n",
    "\n",
    "# Save the trained model\n",
    "output_dir = \"archive/updated_CompanyModel_py\"\n",
    "nlp.to_disk(output_dir)\n",
    "\n",
    "print(\"NER model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e15398-d9fc-4d8f-8dd5-9b789c3816ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
